{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks (GANs) using PyTorch\n",
    "\n",
    "In the following demos we will explore, each technique (GANs, VAEs, and Diffusion Models) by its own code since each one of them involves distinct architectures and training procedures. \n",
    "\n",
    "Below is a basic outline and simplified implementation for each approach using popular libraries like TensorFlow/Keras and PyTorch. These examples are rudimentary and meant for educational purposes to provide a starting point for deeper exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "GANs consist of two neural networks:\n",
    "\n",
    "1. **Generator:** Generates fake data from random noise.\n",
    "2. **Discriminator:** Tries to distinguish between real data and data generated by the Generator.\n",
    "\n",
    "The Generator and Discriminator are trained together in a way that the Generator gets better at creating realistic data, while the Discriminator gets better at telling the real data apart from the fake dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Generator and Discriminator functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 28*28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(x.size(0), 1, 28, 28)\n",
    "    \n",
    "\n",
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize networks\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the loss and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "mnist = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        real = torch.ones(imgs.size(0), 1)\n",
    "        fake = torch.zeros(imgs.size(0), 1)\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_d.zero_grad()\n",
    "        outputs = discriminator(imgs)\n",
    "        loss_real = criterion(outputs, real)\n",
    "        z = torch.randn(imgs.size(0), latent_dim)\n",
    "        fake_imgs = generator(z)\n",
    "        outputs = discriminator(fake_imgs.detach())\n",
    "        loss_fake = criterion(outputs, fake)\n",
    "        loss_d = loss_real + loss_fake\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_g.zero_grad()\n",
    "        outputs = discriminator(fake_imgs)\n",
    "        loss_g = criterion(outputs, real)\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss D: {loss_d.item():.4f}, Loss G: {loss_g.item():.4f}')\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        save_image(fake_imgs.data[:25], f'images_{epoch}.png', nrow=5, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
